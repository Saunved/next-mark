Humanity tends to overfit trends.

It's as if everytime we invent a new piece of technology, there is a small set of people doing useful things with it, and a loud majority looking to book profits off the hype (even through scams - yes, I'm looking at you NFTs).

Generative AI coding falls squarely in the hype bucket for me.

Having AI write business logic for you is like a trainee pilot being given a commercial jet-liner. The only problem is, many businesses, don't understand how bad the aftermath is going to be.

In its current state, AI writing code will do two things:
1. Massively improve short-term productivity, and allow devs to ship 2-10x faster, and as a result, it will -
2. Accelerate tech debt and production bugs at astronomical rates.

This will, in turn, result in brownfield applications, running in production, with live users, and the following issues:
1. Security vulnerabilities that would make your users shiver.
2. An increase in demand for senior engineers for -
3. Large code rewrites that pull back the pace of development, potentially worse than if AI had never written it.
4. Junior developers who need a detox from AI coding tools.
5. Increased demand for QA and DevOps engineers, due to -
6. Software that breaks frequently.

The issue at hand is of context and verifiability. How much context can a LLM keep track of when writing code, which context should it keep, and how can it verify that its output is correct?

I believe that AI verifying its output (even with the help of another AI) is akin to the halting problem. We don't have a way to be sure without human intervention - this is of course assuming that AI reasoning does not surpass human cognition by miles any time soon.

Here's how I think the vibe coding hype will correct:
1. AI will act more like a linter than a code writer. There are already AI linting tools out there, and I believe most major linters will incorporate valid AI features soon.
2. AI will focus on assisting in the truest sense. That means pointing out functions that can be reused, highlighting a potentially missed test case, or suggesting an optimization. AI will prompt *you* - which I've always thought is a fantastic and underutilized use case.
3. Traditional earch engines will have limited use cases, and AI will be used to cite and summarise everything you search. It's not clear who will win this race, but it's clear that this is the future of search.
4. Instead of SEO, we will see a rise in AISO (AI search optimizations) potentially managed with hidden, structured data in markup. We'll probably get an entire ecosystem of tools for this, similar to how we have for SEO, with an overlap with OpenGraph.
5. On-device AI models will keep getting better, communicating with cloud models only for compute-intensive tasks.
6. Products that used AI for marketing will slowly shift away from the narrative, towards positioning AI as a feature rather than AI as THE feature.
7. A lot of AI-based copy-cat companies will see a slow death as the established companies catch up, but with the backing of the rich data they already have.